{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from keras.layers import Conv2D, Dense, Activation\n",
    "from functools import reduce\n",
    "from keras.models import Sequential\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting directory list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = Image.open('./fish/220px-Alligator_Gar_10.JPG.jpg', \"r\")\n",
    "# d = 'fish/'\n",
    "d = 'created-data/'\n",
    "dirs = [d + x.strip(' ') + '/' for x in os.listdir(d)]\n",
    "temp = []\n",
    "\n",
    "# Removing DS store\n",
    "for d in dirs:\n",
    "    if d == 'fish/.DS_Store':\n",
    "        continue\n",
    "    temp.append(d)\n",
    "dirs = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading each image in a directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading images for: created-data/bluegill/\n",
      "Start loading images for: created-data/smallmouth_bass/\n",
      "Start loading images for: created-data/blue_catfish/\n",
      "Start loading images for: created-data/walleye/\n",
      "Start loading images for: created-data/black_crappie/\n",
      "Start loading images for: created-data/channel_catfish/\n",
      "Start loading images for: created-data/alligator_gar/\n",
      "Start loading images for: created-data/largemouth_bass/\n",
      "Start loading images for: created-data/rainbow_trout/\n",
      "Start loading images for: created-data/common_carp/\n",
      "Start loading images for: created-data/green_sunfish/\n",
      "Start loading images for: created-data/northern_pike/\n"
     ]
    }
   ],
   "source": [
    "def get_image_dict():\n",
    "    fish_data = {}\n",
    "\n",
    "    for directory in dirs:\n",
    "        try:\n",
    "            dir_files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "        except NotADirectoryError:\n",
    "            continue\n",
    "\n",
    "        images = []\n",
    "        print(\"Start loading images for: \" + directory)\n",
    "        for image_file in dir_files:\n",
    "            try:\n",
    "                f = Image.open(directory + image_file)\n",
    "                img_as_arr = np.array(f.resize((256,256)))\n",
    "                images.append(img_as_arr)\n",
    "                f.close()\n",
    "            except OSError:\n",
    "                continue\n",
    "        fish_data[directory.split(\"/\")[1]] = images\n",
    "    return fish_data\n",
    "\n",
    "fish_data = get_image_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_vec(fish_data):\n",
    "    \"\"\"\n",
    "    :returns: x_train, y_train\n",
    "    \"\"\"\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for key in fish_data:\n",
    "        data = fish_data[key]\n",
    "        \n",
    "        samples = []\n",
    "        for image in data:\n",
    "            if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "                continue\n",
    "            samples.append(image)\n",
    "\n",
    "        shape = (len(samples),) + data[0].shape\n",
    "\n",
    "        x_placeholder = np.zeros(shape)\n",
    "        \n",
    "\n",
    "        for i, sample in enumerate(samples):\n",
    "            x_placeholder[i] = sample\n",
    "        \n",
    "        x_train.append(x_placeholder)\n",
    "        y_train.append(key)\n",
    "        \n",
    "    return x_train, y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vec, labels = dict_to_vec(fish_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipped_list = list(zip(x_train_vec, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# , [labels[0]]\n",
    "# list(zip(x_train_vec, labels))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('training_data.pkl', 'wb') as f:\n",
    "#     pickle.dump(zippped_list, f)\n",
    "#     f.close()\n",
    "\n",
    "# with open('training_data.pkl', 'r') as f:\n",
    "#     pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing walleye\n",
    "if x_train_vec[3].shape[0] < 1000:\n",
    "    x_train_vec.pop(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1000, 256, 256, 3),\n",
       " (1000, 256, 256, 3),\n",
       " (1000, 256, 256, 3),\n",
       " (1000, 256, 256, 3),\n",
       " (1000, 256, 256, 3),\n",
       " (1000, 256, 256, 3),\n",
       " (1000, 256, 256, 3),\n",
       " (1000, 256, 256, 3),\n",
       " (1000, 256, 256, 3),\n",
       " (1000, 256, 256, 3),\n",
       " (1000, 256, 256, 3)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.shape for x in x_train_vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_num_index = []\n",
    "for i in range(len(x_train_vec)):\n",
    "    list_num_index.append(x_train_vec[i].shape[0])\n",
    "list_num_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_train_vec)):\n",
    "    x_train_vec[i] = x_train_vec[i][0:1000,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_num_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.zeros((len(x_train_vec)*1000))\n",
    "for i in range(len(list_num_index)):\n",
    "    y[i*1000:(i+1)*1000] = i\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate(x_train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_, X_test, y_train, y_test = train_test_split(x_train, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-3767571d9852>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_' is not defined"
     ]
    }
   ],
   "source": [
    "print(X_train_.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x_train[0:2]\n",
    "x2 = x_train[5000:]\n",
    "y1 = y[0:2]\n",
    "y2 = y[5000:]\n",
    "with open('keras_model/train1.pkl', 'wb') as handle:\n",
    "    pickle.dump((x_train[:5000], y[:5000]), handle, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('keras_model/train2.pkl', 'wb') as handle:\n",
    "    pickle.dump((x_train[5000:], y[5000:]), handle, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('keras_model/test.pkl', 'wb') as handle:\n",
    "    pickle.dump((X_test, y_test), handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(880, 256, 256, 3)\n",
      "(748,)\n"
     ]
    }
   ],
   "source": [
    "# pickle.dump(x_train, 'x_train')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'channels': 3,\n",
    "    'window': 5,\n",
    "    'stride': 3,\n",
    "    'padding': 'same',\n",
    "    'activation': 'relu'\n",
    "}\n",
    "\n",
    "channels = parameters['channels']\n",
    "window = parameters['window']\n",
    "stride = parameters['stride']\n",
    "padding = parameters['padding']\n",
    "activation = parameters['activation']\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# magic numbers: 256 * 256 * 3 is the total pixels per image\n",
    "model.add(Dense((256 * 256 * 3), input_shape=x_train.shape))\n",
    "\n",
    "model.add(Conv2D(filters=channels, kernel_size=window, strides=stride, padding=padding, activation=activation,\n",
    "    data_format='channels_last'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
