{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from keras.layers import Conv2D, Dense, Activation\n",
    "from functools import reduce\n",
    "from keras.models import Sequential\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting directory list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = Image.open('./fish/220px-Alligator_Gar_10.JPG.jpg', \"r\")\n",
    "# d = 'fish/'\n",
    "d = 'created-data/'\n",
    "dirs = [d + x.strip(' ') + '/' for x in os.listdir(d)]\n",
    "temp = []\n",
    "\n",
    "# Removing DS store\n",
    "for d in dirs:\n",
    "    if d == 'fish/.DS_Store':\n",
    "        continue\n",
    "    temp.append(d)\n",
    "dirs = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading each image in a directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading images for: created-data/bluegill/\n",
      "Start loading images for: created-data/smallmouth_bass/\n",
      "Start loading images for: created-data/blue_catfish/\n",
      "Start loading images for: created-data/walleye/\n",
      "Start loading images for: created-data/black_crappie/\n",
      "Start loading images for: created-data/channel_catfish/\n",
      "Start loading images for: created-data/alligator_gar/\n",
      "Start loading images for: created-data/largemouth_bass/\n",
      "Start loading images for: created-data/rainbow_trout/\n",
      "Start loading images for: created-data/common_carp/\n",
      "Start loading images for: created-data/green_sunfish/\n",
      "Start loading images for: created-data/northern_pike/\n"
     ]
    }
   ],
   "source": [
    "def get_image_dict():\n",
    "    fish_data = {}\n",
    "\n",
    "    for directory in dirs:\n",
    "        try:\n",
    "            dir_files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "        except NotADirectoryError:\n",
    "            continue\n",
    "\n",
    "        images = []\n",
    "        print(\"Start loading images for: \" + directory)\n",
    "        for image_file in dir_files:\n",
    "            try:\n",
    "                f = Image.open(directory + image_file)\n",
    "                img_as_arr = np.array(f.resize((256,256)))\n",
    "                images.append(img_as_arr)\n",
    "                f.close()\n",
    "            except OSError:\n",
    "                continue\n",
    "        fish_data[directory.split(\"/\")[1]] = images\n",
    "    return fish_data\n",
    "\n",
    "fish_data = get_image_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_vec(fish_data):\n",
    "    \"\"\"\n",
    "    :returns: x_train, y_train\n",
    "    \"\"\"\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for key in fish_data:\n",
    "        data = fish_data[key]\n",
    "        \n",
    "        samples = []\n",
    "        for image in data:\n",
    "            if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "                continue\n",
    "            samples.append(image)\n",
    "\n",
    "        shape = (len(samples),) + data[0].shape\n",
    "\n",
    "        x_placeholder = np.zeros(shape)\n",
    "\n",
    "        for i, sample in enumerate(samples):\n",
    "            x_placeholder[i] = sample\n",
    "        \n",
    "        x_train.append(x_placeholder)\n",
    "        y_train.append(key)\n",
    "        \n",
    "    return x_train, y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vec, labels = dict_to_vec(fish_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipped_list = list(zip(x_train_vec, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# , [labels[0]]\n",
    "# list(zip(x_train_vec, labels))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('training_data.pkl', 'wb') as f:\n",
    "#     pickle.dump(zippped_list, f)\n",
    "#     f.close()\n",
    "\n",
    "# with open('training_data.pkl', 'r') as f:\n",
    "#     pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[158., 130.,  82.],\n",
       "         [151., 120.,  73.],\n",
       "         [170., 138.,  89.],\n",
       "         ...,\n",
       "         [176., 147., 115.],\n",
       "         [203., 174., 132.],\n",
       "         [199., 168., 121.]],\n",
       "\n",
       "        [[194., 170.,  98.],\n",
       "         [172., 145.,  74.],\n",
       "         [173., 145.,  72.],\n",
       "         ...,\n",
       "         [228., 205., 161.],\n",
       "         [200., 177., 125.],\n",
       "         [197., 173., 113.]],\n",
       "\n",
       "        [[194., 170.,  98.],\n",
       "         [172., 145.,  74.],\n",
       "         [173., 145.,  72.],\n",
       "         ...,\n",
       "         [228., 205., 161.],\n",
       "         [200., 177., 125.],\n",
       "         [197., 173., 113.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 75.,  70.,  66.],\n",
       "         [ 75.,  70.,  66.],\n",
       "         [ 74.,  69.,  65.],\n",
       "         ...,\n",
       "         [ 79.,  74.,  70.],\n",
       "         [ 80.,  75.,  71.],\n",
       "         [ 80.,  75.,  71.]],\n",
       "\n",
       "        [[ 75.,  70.,  66.],\n",
       "         [ 75.,  70.,  66.],\n",
       "         [ 74.,  69.,  65.],\n",
       "         ...,\n",
       "         [ 79.,  74.,  70.],\n",
       "         [ 80.,  75.,  71.],\n",
       "         [ 80.,  75.,  71.]],\n",
       "\n",
       "        [[ 74.,  69.,  65.],\n",
       "         [ 73.,  68.,  64.],\n",
       "         [ 73.,  68.,  64.],\n",
       "         ...,\n",
       "         [ 79.,  74.,  70.],\n",
       "         [ 80.,  75.,  71.],\n",
       "         [ 80.,  75.,  71.]]],\n",
       "\n",
       "\n",
       "       [[[ 10.,  11.,  15.],\n",
       "         [ 10.,  11.,  15.],\n",
       "         [ 10.,  11.,  15.],\n",
       "         ...,\n",
       "         [ 10.,  11.,  15.],\n",
       "         [ 10.,  11.,  15.],\n",
       "         [ 10.,  11.,  15.]],\n",
       "\n",
       "        [[ 10.,  11.,  15.],\n",
       "         [ 10.,  11.,  15.],\n",
       "         [ 10.,  11.,  15.],\n",
       "         ...,\n",
       "         [ 10.,  11.,  15.],\n",
       "         [ 10.,  11.,  15.],\n",
       "         [ 10.,  11.,  15.]],\n",
       "\n",
       "        [[ 10.,  11.,  15.],\n",
       "         [ 10.,  11.,  15.],\n",
       "         [ 10.,  11.,  15.],\n",
       "         ...,\n",
       "         [ 10.,  11.,  15.],\n",
       "         [ 10.,  11.,  15.],\n",
       "         [ 10.,  11.,  15.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[223., 199., 163.],\n",
       "         [225., 201., 167.],\n",
       "         [219., 195., 161.],\n",
       "         ...,\n",
       "         [188., 174., 174.],\n",
       "         [193., 181., 183.],\n",
       "         [197., 188., 189.]],\n",
       "\n",
       "        [[227., 202., 162.],\n",
       "         [226., 200., 163.],\n",
       "         [229., 203., 166.],\n",
       "         ...,\n",
       "         [191., 177., 177.],\n",
       "         [196., 184., 186.],\n",
       "         [203., 194., 195.]],\n",
       "\n",
       "        [[226., 202., 158.],\n",
       "         [229., 204., 163.],\n",
       "         [226., 201., 161.],\n",
       "         ...,\n",
       "         [194., 180., 180.],\n",
       "         [199., 187., 189.],\n",
       "         [204., 195., 196.]]],\n",
       "\n",
       "\n",
       "       [[[ 30.,  34.,  45.],\n",
       "         [ 30.,  34.,  45.],\n",
       "         [ 31.,  35.,  46.],\n",
       "         ...,\n",
       "         [ 25.,  33.,  36.],\n",
       "         [ 25.,  33.,  36.],\n",
       "         [ 25.,  33.,  36.]],\n",
       "\n",
       "        [[ 28.,  32.,  43.],\n",
       "         [ 28.,  32.,  43.],\n",
       "         [ 26.,  30.,  41.],\n",
       "         ...,\n",
       "         [ 25.,  33.,  36.],\n",
       "         [ 25.,  33.,  36.],\n",
       "         [ 25.,  33.,  36.]],\n",
       "\n",
       "        [[ 30.,  34.,  45.],\n",
       "         [ 30.,  34.,  45.],\n",
       "         [ 25.,  29.,  40.],\n",
       "         ...,\n",
       "         [ 25.,  33.,  36.],\n",
       "         [ 25.,  33.,  36.],\n",
       "         [ 25.,  33.,  36.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[141., 132., 117.],\n",
       "         [141., 132., 117.],\n",
       "         [139., 130., 115.],\n",
       "         ...,\n",
       "         [ 23.,  31.,  34.],\n",
       "         [ 23.,  31.,  34.],\n",
       "         [ 23.,  31.,  34.]],\n",
       "\n",
       "        [[119., 110.,  93.],\n",
       "         [119., 110.,  93.],\n",
       "         [120., 111.,  94.],\n",
       "         ...,\n",
       "         [ 23.,  31.,  34.],\n",
       "         [ 23.,  31.,  34.],\n",
       "         [ 23.,  31.,  34.]],\n",
       "\n",
       "        [[141., 132., 115.],\n",
       "         [141., 132., 115.],\n",
       "         [137., 128., 111.],\n",
       "         ...,\n",
       "         [ 23.,  31.,  34.],\n",
       "         [ 23.,  31.,  34.],\n",
       "         [ 23.,  31.,  34.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[138., 132.,  98.],\n",
       "         [112., 103.,  70.],\n",
       "         [114.,  99.,  68.],\n",
       "         ...,\n",
       "         [106.,  92., 107.],\n",
       "         [ 96.,  82.,  97.],\n",
       "         [113.,  99., 114.]],\n",
       "\n",
       "        [[138., 132.,  98.],\n",
       "         [112., 103.,  70.],\n",
       "         [114.,  99.,  68.],\n",
       "         ...,\n",
       "         [106.,  92., 107.],\n",
       "         [ 96.,  82.,  97.],\n",
       "         [113.,  99., 114.]],\n",
       "\n",
       "        [[117., 111.,  77.],\n",
       "         [122., 113.,  80.],\n",
       "         [123., 108.,  77.],\n",
       "         ...,\n",
       "         [108.,  94., 109.],\n",
       "         [104.,  90., 103.],\n",
       "         [107.,  93., 106.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[227., 199., 152.],\n",
       "         [226., 198., 151.],\n",
       "         [229., 201., 154.],\n",
       "         ...,\n",
       "         [178., 150., 110.],\n",
       "         [184., 157., 114.],\n",
       "         [180., 153., 110.]],\n",
       "\n",
       "        [[225., 197., 150.],\n",
       "         [218., 190., 143.],\n",
       "         [215., 187., 140.],\n",
       "         ...,\n",
       "         [205., 177., 137.],\n",
       "         [200., 173., 130.],\n",
       "         [181., 154., 111.]],\n",
       "\n",
       "        [[225., 197., 150.],\n",
       "         [218., 190., 143.],\n",
       "         [215., 187., 140.],\n",
       "         ...,\n",
       "         [205., 177., 137.],\n",
       "         [200., 173., 130.],\n",
       "         [181., 154., 111.]]],\n",
       "\n",
       "\n",
       "       [[[107., 101., 105.],\n",
       "         [117., 115., 116.],\n",
       "         [151., 150., 148.],\n",
       "         ...,\n",
       "         [195., 171., 159.],\n",
       "         [194., 166., 154.],\n",
       "         [193., 165., 153.]],\n",
       "\n",
       "        [[ 98.,  92.,  94.],\n",
       "         [111., 107., 124.],\n",
       "         [144., 144., 154.],\n",
       "         ...,\n",
       "         [191., 167., 155.],\n",
       "         [192., 164., 152.],\n",
       "         [189., 161., 149.]],\n",
       "\n",
       "        [[122., 116.,  92.],\n",
       "         [126., 118., 131.],\n",
       "         [139., 138., 152.],\n",
       "         ...,\n",
       "         [193., 170., 164.],\n",
       "         [191., 164., 155.],\n",
       "         [192., 162., 154.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[108.,  89.,  72.],\n",
       "         [ 94.,  81.,  62.],\n",
       "         [ 96.,  83.,  66.],\n",
       "         ...,\n",
       "         [109., 108., 124.],\n",
       "         [134., 126., 137.],\n",
       "         [112., 118., 134.]],\n",
       "\n",
       "        [[120., 102.,  82.],\n",
       "         [114.,  96.,  76.],\n",
       "         [117., 100.,  80.],\n",
       "         ...,\n",
       "         [ 86., 103., 119.],\n",
       "         [115., 120., 139.],\n",
       "         [ 95., 104., 119.]],\n",
       "\n",
       "        [[129., 111.,  91.],\n",
       "         [131., 113.,  93.],\n",
       "         [131., 108.,  90.],\n",
       "         ...,\n",
       "         [ 94., 105., 123.],\n",
       "         [112., 130., 142.],\n",
       "         [ 86., 107., 124.]]],\n",
       "\n",
       "\n",
       "       [[[ 50.,  66.,  55.],\n",
       "         [ 50.,  66.,  55.],\n",
       "         [ 53.,  67.,  54.],\n",
       "         ...,\n",
       "         [174., 142.,  95.],\n",
       "         [183., 150., 105.],\n",
       "         [183., 150., 105.]],\n",
       "\n",
       "        [[ 50.,  66.,  55.],\n",
       "         [ 50.,  66.,  55.],\n",
       "         [ 53.,  67.,  54.],\n",
       "         ...,\n",
       "         [174., 142.,  95.],\n",
       "         [183., 150., 105.],\n",
       "         [183., 150., 105.]],\n",
       "\n",
       "        [[ 52.,  69.,  53.],\n",
       "         [ 52.,  69.,  53.],\n",
       "         [ 52.,  66.,  51.],\n",
       "         ...,\n",
       "         [150., 119.,  73.],\n",
       "         [134., 103.,  57.],\n",
       "         [134., 103.,  57.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[159., 127.,  68.],\n",
       "         [159., 127.,  68.],\n",
       "         [158., 128.,  74.],\n",
       "         ...,\n",
       "         [127., 131., 116.],\n",
       "         [123., 127., 112.],\n",
       "         [123., 127., 112.]],\n",
       "\n",
       "        [[176., 142.,  81.],\n",
       "         [176., 142.,  81.],\n",
       "         [148., 117.,  62.],\n",
       "         ...,\n",
       "         [132., 136., 111.],\n",
       "         [126., 132., 106.],\n",
       "         [126., 132., 106.]],\n",
       "\n",
       "        [[176., 142.,  81.],\n",
       "         [176., 142.,  81.],\n",
       "         [148., 117.,  62.],\n",
       "         ...,\n",
       "         [132., 136., 111.],\n",
       "         [126., 132., 106.],\n",
       "         [126., 132., 106.]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing walleye\n",
    "x_train_vec.pop(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = np.concatenate(x_train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 256, 256, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros((len(x_train_vec)*1000))\n",
    "for i in range(len(x_train_vec)):\n",
    "    y[i*1000:(i+1)*1000] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_, X_test, y_train, y_test = train_test_split(x_train, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.pkl', 'wb') as handle:\n",
    "    pickle.dump((X_train_, y_train), handle)\n",
    "with open('test.pkl', 'wb') as handle:\n",
    "    pickle.dump((X_test, y_test), handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11084, 256, 256, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pickle.dump(x_train, 'x_train')\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv2d_11: expected ndim=4, found ndim=5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-357-a2d4a6351cb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m model.add(Conv2D(filters=channels, kernel_size=window, strides=stride, padding=padding, activation=activation,\n\u001b[0;32m---> 21\u001b[0;31m     data_format='channels_last'))\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    490\u001b[0m                           output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    491\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    470\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    473\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv2d_11: expected ndim=4, found ndim=5"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'channels': 3,\n",
    "    'window': 5,\n",
    "    'stride': 3,\n",
    "    'padding': 'same',\n",
    "    'activation': 'relu'\n",
    "}\n",
    "\n",
    "channels = parameters['channels']\n",
    "window = parameters['window']\n",
    "stride = parameters['stride']\n",
    "padding = parameters['padding']\n",
    "activation = parameters['activation']\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# magic numbers: 256 * 256 * 3 is the total pixels per image\n",
    "model.add(Dense((256 * 256 * 3), input_shape=x_train.shape))\n",
    "\n",
    "model.add(Conv2D(filters=channels, kernel_size=window, strides=stride, padding=padding, activation=activation,\n",
    "    data_format='channels_last'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
